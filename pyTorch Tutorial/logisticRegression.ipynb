{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b47ab6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9a56598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bc = datasets.load_breast_cancer()\n",
    "x , y = bc.data , bc.target\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "faf79122",
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_samples:-(569) how many data points do we have \n",
    "#n_features:-(30) how many fetures we  need to train\n",
    "n_samples , n_features = x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ce4bb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train , x_test , y_train , y_test = train_test_split(x , y , test_size = 0.2 , random_state = 1234)\n",
    "# random_state :- controls the shuffling process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94cbe737",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# standard scaler will scale our data into a specific range , that is why we need to fit the training data\n",
    "# now we need to scale the testing data accordingly to the training data\n",
    "# so we'll just transform the testing data \n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "170560de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one thing to note everything right now is in numpy array\n",
    "# we need to convert it into tensors \n",
    "\n",
    "x_train = torch.from_numpy(x_train.astype(np.float32))\n",
    "x_test = torch.from_numpy(x_test.astype(np.float32))\n",
    "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "686761b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.]]) tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.]])\n"
     ]
    }
   ],
   "source": [
    "y_train = y_train.view(y_train.shape[0], 1)\n",
    "y_test = y_test.view(y_test.shape[0], 1)\n",
    "print(y_train , y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1f4b2296",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_input_features):\n",
    "        super(Model, self).__init__()\n",
    "        self.linear = nn.Linear(n_input_features, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y_pred = torch.sigmoid(self.linear(x))\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "11abc0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = n_features\n",
    "output_size = 1\n",
    "model = Model(n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7fd86a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters() , lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2106be41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:- 0.03318929672241211\n",
      "loss:- 0.033053334802389145\n",
      "loss:- 0.032919563353061676\n",
      "loss:- 0.03278793767094612\n",
      "loss:- 0.032658398151397705\n",
      "loss:- 0.03253088891506195\n",
      "loss:- 0.03240535408258438\n",
      "loss:- 0.032281745225191116\n",
      "loss:- 0.03216001018881798\n",
      "loss:- 0.032040104269981384\n",
      "loss:- 0.031921982765197754\n",
      "loss:- 0.03180559352040291\n",
      "loss:- 0.03169090673327446\n",
      "loss:- 0.03157787024974823\n",
      "loss:- 0.03146645426750183\n",
      "loss:- 0.031356606632471085\n",
      "loss:- 0.031248297542333603\n",
      "loss:- 0.03114149160683155\n",
      "loss:- 0.031036149710416794\n",
      "loss:- 0.030932245776057243\n",
      "loss:- 0.030829736962914467\n",
      "loss:- 0.030728604644536972\n",
      "loss:- 0.030628805980086327\n",
      "loss:- 0.030530311167240143\n",
      "loss:- 0.03043309971690178\n",
      "loss:- 0.03033713810145855\n",
      "loss:- 0.030242398381233215\n",
      "loss:- 0.030148860067129135\n",
      "loss:- 0.030056485906243324\n",
      "loss:- 0.029965264722704887\n",
      "loss:- 0.02987516298890114\n",
      "loss:- 0.029786160215735435\n",
      "loss:- 0.029698237776756287\n",
      "loss:- 0.029611365869641304\n",
      "loss:- 0.029525525867938995\n",
      "loss:- 0.029440702870488167\n",
      "loss:- 0.02935687080025673\n",
      "loss:- 0.02927400730550289\n",
      "loss:- 0.02919210121035576\n",
      "loss:- 0.029111124575138092\n",
      "loss:- 0.029031066223978996\n",
      "loss:- 0.028951911255717278\n",
      "loss:- 0.028873629868030548\n",
      "loss:- 0.02879621647298336\n",
      "loss:- 0.028719652444124222\n",
      "loss:- 0.02864392288029194\n",
      "loss:- 0.02856900542974472\n",
      "loss:- 0.02849489077925682\n",
      "loss:- 0.028421567752957344\n",
      "loss:- 0.02834901213645935\n",
      "loss:- 0.028277218341827393\n",
      "loss:- 0.028206169605255127\n",
      "loss:- 0.02813585102558136\n",
      "loss:- 0.028066251426935196\n",
      "loss:- 0.02799736149609089\n",
      "loss:- 0.027929162606596947\n",
      "loss:- 0.02786164917051792\n",
      "loss:- 0.02779480442404747\n",
      "loss:- 0.027728622779250145\n",
      "loss:- 0.027663083747029305\n",
      "loss:- 0.0275981854647398\n",
      "loss:- 0.027533911168575287\n",
      "loss:- 0.02747025340795517\n",
      "loss:- 0.02740720473229885\n",
      "loss:- 0.027344750240445137\n",
      "loss:- 0.02728288061916828\n",
      "loss:- 0.027221590280532837\n",
      "loss:- 0.02716086059808731\n",
      "loss:- 0.027100693434476852\n",
      "loss:- 0.027041077613830566\n",
      "loss:- 0.026982000097632408\n",
      "loss:- 0.02692345716059208\n",
      "loss:- 0.026865435764193535\n",
      "loss:- 0.026807932183146477\n",
      "loss:- 0.02675093710422516\n",
      "loss:- 0.026694443076848984\n",
      "loss:- 0.026638438925147057\n",
      "loss:- 0.02658291906118393\n",
      "loss:- 0.026527879759669304\n",
      "loss:- 0.026473311707377434\n",
      "loss:- 0.026419205591082573\n",
      "loss:- 0.026365559548139572\n",
      "loss:- 0.026312358677387238\n",
      "loss:- 0.026259608566761017\n",
      "loss:- 0.02620728872716427\n",
      "loss:- 0.02615540660917759\n",
      "loss:- 0.026103945448994637\n",
      "loss:- 0.02605290710926056\n",
      "loss:- 0.026002276688814163\n",
      "loss:- 0.0259520523250103\n",
      "loss:- 0.02590223401784897\n",
      "loss:- 0.025852808728814125\n",
      "loss:- 0.02580377645790577\n",
      "loss:- 0.025755127891898155\n",
      "loss:- 0.025706859305500984\n",
      "loss:- 0.02565896511077881\n",
      "loss:- 0.02561144158244133\n",
      "loss:- 0.02556428126990795\n",
      "loss:- 0.025517482310533524\n",
      "loss:- 0.02547103352844715\n",
      "predicted:- tensor([0.6506], grad_fn=<SelectBackward0>) actual value:- tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(no_epochs):\n",
    "    \n",
    "    # forward prop:-\n",
    "    y_pred = model.forward(x_train)\n",
    "    \n",
    "    # loss:- \n",
    "    l = loss(y_pred , y_train)\n",
    "    # backwardPass\n",
    "    l.backward()\n",
    "    #update weights\n",
    "    optimizer.step()\n",
    "    #set gradients to zero\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if (epoch+1)%10 == 0:\n",
    "        weights_bias = model.parameters()\n",
    "        weights = list(weights_bias)\n",
    "        print(\"loss:-\" , l.item())\n",
    "print(\"predicted:-\" , y_pred[0] , \"actual value:-\" , y_train[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
